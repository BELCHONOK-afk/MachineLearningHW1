# Линейный регрессор с интерфейсом. Описание процесса

## EDA

В начале предоставлю информацию о датасетах:

**df_train**

 |#   |Column       |  Non-Null Count  |Dtype  
---|------      |   -------------- | -----  
 0 |  name     |      6999 non-null   |object 
 1 | year       |    6999 non-null   |int64  
 2 |  selling_price | 6999 non-null   |int64  
 3 |  km_driven      |6999 non-null   |int64  
 4 |  fuel           |6999 non-null   |object 
 5 |  seller_type    |6999 non-null   |object 
 6 |  transmission   |6999 non-null   |object 
 7  | owner          |6999 non-null   |object 
 8   |mileage        |6797 non-null   |object 
 9   |engine         |6797 non-null  |object 
 10  |max_power      |6803 non-null  | object 
 11  |torque         |6796 non-null  | object 
 12  |seats          |6797 non-null  | float64

**df_test**

|#  | Column     |    Non-Null Count | Dtype  
---  |------|         --------------|  -----  
 0  | name|           1000 non-null|   object 
 1  | year           |1000 non-null  | int64  
 2   |selling_price | 1000 non-null  | int64  
 3  | km_driven     | 1000 non-null  | int64  
 4  | fuel          | 1000 non-null  | object 
 5 |  seller_type  |  1000 non-null  | object 
 6  | transmission |  1000 non-null |  object 
 7 | owner         | 1000 non-null  | object 
 8  | mileage     |   981 non-null  |  object 
 9  | engine       |  981 non-null  |  object 
 10 | max_power    |  981 non-null  |  object 
 11 | torque       |  981 non-null   | object 
 12|  seats        |  981 non-null  |  float64

В ходе анализа данных были произведены следующие действия: 

* Были заполнены все недостающие данные в следующих колонках: 

**df_train**
* mileage
* engine
* max_power
* torque
* seats

**df_test**
* mileage
* engine
* max_power
* torque
* seats

Заполнение было произведено медианой (первой модой в случае категориальных признаков)

* После этого были удалены все дубликаты (исключая целевую колонку - selling_price)

* Числовые данные (mileage, engine, max_power) были представлены с использованием размерности - в начале привел все к одной размерности (колонка mileage, привел к kmpl путем умножения на 1.4), после чего эти столбцы были очищены от размерностей и переведены к вещественному типу данных. Колонка torque была удалена из-за своей сложности

* Далее была проведена визуализация данных с использованием pairplot для выдвижения гипотез о зависимости данных на тренировочных и тестовых датасетах. В результате были выдвинуты следующие гипотезы: 

**Зависимости целевой переменной от признаков**

* Зависимость от года выпуска: на распределении видно, что данные имеют экспоненциальную зависимость 

* Зависимость от пробега (в км): имеет обратную экспоненциальную зависимость

* Заисимость от пробега в милях напоминает нормальной распределение,так как данные сгруппированы в центральной части графика

* Зависимость от объема двигвтеля - с увеличением объема двигателя увеличивается цена

Можно предположить о следующих корреляциях: 

положительная:

* цена - год выпуска
* цена - объем двигателя

отрицательная: 

* цена - расход топлива 
* также наблюдается зависимость расхода топлива от объема двигателя

Распределения в разбивке на трейн и тест оказались похожи, но не везде. На многих распределения в тестовой выьорке оказалось больше распределений, показывающих зависимости

* Для проверки выдвинутых гипотез была построена матрица корреляции на тренировочных данных. Из нее были сделаны следующие выводы:
** Наименее скоррелированы между собой год выпуска и объем двигателя 
** Довольно сильная положительная корреляция наблюдается между объемом двигателя и числом сидений, объемом двигателя и максимальной мощностью 
** По вычисленной матрице корреляции между годом и пробегом в километрах наьлюдается отрицательная корреляция, из чего можно сделать вывод, что чем меньше год, тем больше пробег в километрах, но зависимость не ярко выражена (менее 0.5), поэтому связь не сильная
** Матрица корреляции подтвердила выдвинутые гипотезы

* Также были построены "ящики с усами" для проверки на выбросы. Оказалось, что целевая переменная имеет неравномерное распределение и достаточно большое число выбросов. Поэтому было принято решение ввести логарифм от целевой переменной и по ней производить построение моделей.

## Построение моделей на вещественных признаках

В начале из тренировочного и тестового датасетов были выбраны только вещественные признаки (year, km_driven,	mileage,	engine,	max_power,	seats).

Для удобства и повышения читаемости кода были введены три функции - plot_true_vs_pred, plot_subplots, model_metrics - выводящие графики реальных данных и предсказанных и метрики модели ($R^2$, MSE, MAE - так как она менее чувствительна к выбросам), соответственно. 

### Классическая линейная регрессия LinearRegression

Были созданы три модели классической линейной регрессии:

* На данных без логарифмирования и масштабирования
* На данных с логарифмированием
* На данных с масштабированием и логарифмированием

Ожидаемо, модели на масштабированных и логарифмированных данных показали лучший результат

- *R2 for train*: 0.7711096191715754
- *R2 for test*: 0.7228803171107241
- *MSE for train*: 0.1337600823770456
- *MSE for test*: 0.19822569316612157
- *MAE for train*: 0.2745040489312344
- *MAE for test*: 0.3368738996695881

Также, проанализировав коэффициенты линейной регрессии, было выявлено, что самым важным признаком является год выпуска с коэффициентом 0.5

### Добавление регуляризации Lasso и ElasticNet. GridSearch

Дальнейшая работа была нацелена на улучшение предсказания путем регуляризации.

В начале была создана простая модель с дефолтным коэффициентом регуляризации $\alpha = 1$. В результате ошибка не убавилась, но было выявлено, что призанки mileage и seats могуть быть отброшены, так как они занулились.

С использованием перебора по сетке с числом фолдов 10 был выявлен оптимальный коэффициент $\alpha = 0.0001$. В таком случае

- *R2 for train*: 0.7711094463270738
- *R2 for test*: 0.7228145465384899
- *MSE for train*: 0.13376018338476248
- *MSE for test*: 0.19827273932731493
- *MAE for train*: 0.27451499223235193
- *MAE for test*: 0.3369008015104531

Далее была проделана аналогичная работы по поиску оптимальных параметров для ElasticNet. Выявленные оптимальные параметры следующие: 'alpha': 0.00343,
'l1_ratio': 1. 

Ошибки следующие: 

- *R2 for train*: 0.7709109918096377
- *R2 for test*: 0.7205053952857519
- *MSE for train*: 0.1338761572081458
- *MSE for test*: 0.199924491750409
- *MAE for train*: 0.27497651262489986
- *MAE for test*: 0.3378323899020861

L1 регуляризация отработала чуть лучше. Но, поскольку, данные были масшитабированы, тысячные доли тоже важны

### Категориальные признаки. Ridge регрессия

В начале был исключен признак Name, так как в нем 1924 уникальных значения и предобработка с использованием OneHotEncoding не представляется возиожной. 

После чего оставшиеся категориальные признаки (fuel, seller_type,	transmission,	owner	seats) были предобработаны методом OneHotEncoding.

После этого были обучены две ridge регрессии с использованием сетки: без масштабирования и с масштабированием.

Ошибки без масштабирования: 

- *R2 for train*: 0.8029076070030656
- *R2 for test*: 0.7819567341755814
- *MSE for train*: 0.11517781842881665
- *MSE for test*: 0.15596790909117664
 - *MAE for train*: 0.25871853743758466
 - *MAE for test*: 0.30822074877335415

 Ошибки с маштабированием:

- *R2 for train*: 0.8030072922174244
- *R2 for test*: 0.7816882691956402
- *MSE for train*: 0.11511956389476354
- *MSE for test*: 0.15615994401336203
- *MAE for train*: 0.25860246814745425
- *MAE for test*: 0.30827670935366963

Самой лучшей моделью по показателям ошибок получилась ridge регрессия с масштабированными признаками

### Бизнес метрика


В задании также был пункт на реализацию бизнес метрики и ее применение к моделям 

Лучше всего отработала классическая линейная регрессия без масштабирования

## FastAPI

Средстваими pydantic был создан класс Item, в котором протипизировал все поля, которые могут быть добавлены как фичи. Также создал класс Items - дочерний от Item, который выводит список объектов Item

Сервис на FastAPI был реализован в соответствии с требованиями

Сервис был протестирован на проверку работоспособности (по всем типам входных данных) и на отлов ошибок. Файлы для тестирования приложены в репозитории, файл-результат в csv формате также прилагаю. 

[Ссылка на скринкаст с работой сервиса](https://drive.google.com/file/d/1qOprO4xtqeSfQ0aZhbsB2rB6E91FZFM6/view?usp=sharing)

